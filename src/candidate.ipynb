{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe6cccd",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab2bdd",
   "metadata": {},
   "source": [
    "On part donc sur Option “Intent TFLite + candidate-driven” :\n",
    "\n",
    "Entraînement Python d’un petit classifieur d’intentions (char-level) → export TFLite.\n",
    "\n",
    "Sur Android : on recharge le modèle TFLite pour prédire l’intent, puis on récupère la valeur par candidate-driven (pas de regex, pas de NER — simple et robuste).\n",
    "\n",
    "Ci-dessous, un notebook découpé par cellules : données → entraînement → export → fichiers à embarquer, + les notes Android pour reproduire la vectorisation et brancher le candidate-driven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3b1bd",
   "metadata": {},
   "source": [
    "Ce qu'on veut faire:\n",
    "\n",
    "- intent_classifier.tflite (modèle compact, quantized).\n",
    "\n",
    "- char_vocab.txt (vocabulaire caractères).\n",
    "\n",
    "- labels.txt (ordre des intents).\n",
    "\n",
    "- Un pipeline Android très léger :\n",
    "\n",
    "    - vectoriser la phrase (caractères → indices via char_vocab.txt),\n",
    "\n",
    "    - Interpreter.run() → intent,\n",
    "\n",
    "    - candidate-driven pour matcher la valeur du champ prédit (cosine n-grammes),\n",
    "\n",
    "    - comparaison à la fiche JSON → OK / INCERTAIN / KO."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e85f4d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d17384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:15:50.509316: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, json, random, unicodedata, re\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "553020ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# Intents (ordre fixe = indices softmax)\n",
    "INTENTS = [\n",
    "    \"PATIENT_IDENTITE\",\n",
    "    \"PATIENT_NAISSANCE\",\n",
    "    \"INTERVENTION_TYPE\",\n",
    "    \"SITE_OPERATOIRE\",\n",
    "    \"HEURE_PREVUE\",\n",
    "    \"CHIRURGIEN\",\n",
    "    \"ANESTHESISTE\",\n",
    "    \"OTHER\"\n",
    "]\n",
    "label2id = {l:i for i,l in enumerate(INTENTS)}\n",
    "id2label = {i:l for l,i in label2id.items()}\n",
    "\n",
    "# Longueur max (en caractères) pour l'entrée du modèle\n",
    "SEQLEN = 200\n",
    "# Vocab max (caractères les + fréquents)\n",
    "VOCAB_SIZE = 300  # suffisant en char-level FR (tu peux monter à 500)\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 64\n",
    "EPOCHS = 10\n",
    "BATCH = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47afb88",
   "metadata": {},
   "source": [
    "# Normalisation \"Android-like\": lowercase, strip accents, espaces uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189dfcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s: str) -> str:\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    s = strip_accents(s)\n",
    "    s = re.sub(r'[^a-z0-9:/ \\-]', ' ', s)  # garde chiffres, :, /, -, espace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9886701",
   "metadata": {},
   "source": [
    "# Dataset minimal (remplace X_raw/y_raw par tes données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a35102e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>type d intervention cholecystectomie</td>\n",
       "      <td>INTERVENTION_TYPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>née le 1956-09-23</td>\n",
       "      <td>PATIENT_NAISSANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>silence en salle</td>\n",
       "      <td>OTHER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on dit patient Alexandre Marchand</td>\n",
       "      <td>PATIENT_IDENTITE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site opératoire genou à droite</td>\n",
       "      <td>SITE_OPERATOIRE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text             intent\n",
       "0  type d intervention cholecystectomie  INTERVENTION_TYPE\n",
       "1                     née le 1956-09-23  PATIENT_NAISSANCE\n",
       "2                      silence en salle              OTHER\n",
       "3     on dit patient Alexandre Marchand   PATIENT_IDENTITE\n",
       "4        site opératoire genou à droite    SITE_OPERATOIRE"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/intent_corpus.tsv\", sep=\"\\t\", header=None, names=[\"text\", \"intent\"], dtype=str)\n",
    "data = data.dropna().sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdc49623",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(normalize_text)\n",
    "data = data[data['intent'].isin(INTENTS)].reset_index(drop=True)\n",
    "data['intent_id'] = data['intent'].apply(lambda x: label2id[x])\n",
    "X = data['text'].tolist()\n",
    "y = data['intent_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a1e07",
   "metadata": {},
   "source": [
    "# Vectoriseur caractères"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0207d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 42\n"
     ]
    }
   ],
   "source": [
    "# On pré-normalise (ci-dessus), donc standardize=None. On découpe en caractères.\n",
    "vectorizer = layers.TextVectorization(\n",
    "    standardize=None,\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQLEN,\n",
    "    max_tokens=VOCAB_SIZE\n",
    ")\n",
    "\n",
    "# Le vectorizer doit voir des textes pour construire le vocab\n",
    "vectorizer.adapt(np.array(X))\n",
    "\n",
    "# Sauvegarde du vocab (indexation identique pour Android)\n",
    "vocab = vectorizer.get_vocabulary()  # vocab[0] = '' (padding), vocab[1] = '[UNK]'\n",
    "with open(\"char_vocab.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "\n",
    "# Prépare les tenseurs d'entrée/sortie\n",
    "X_ids = vectorizer(np.array(X)).numpy()\n",
    "Y_1h = tf.keras.utils.to_categorical(y, num_classes=len(INTENTS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c92983",
   "metadata": {},
   "source": [
    "## Enregister vocab dans un fichier txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48087625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab.txt écrit (42 tokens)\n"
     ]
    }
   ],
   "source": [
    "with open(\"vocab.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "print(f\"vocab.txt écrit ({len(vocab)} tokens)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffec4c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the vectorizer is adapted using the existing X (texts) variable\n",
    "vectorizer.adapt(np.array(X))\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "with open(\"char_vocab.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad69510",
   "metadata": {},
   "source": [
    "# Split + modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f3f2fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ char_ids            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,688</span> │ char_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ char_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ char_ids            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │      \u001b[38;5;34m2,688\u001b[0m │ char_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ char_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,368</span> (28.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,368\u001b[0m (28.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,368</span> (28.78 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,368\u001b[0m (28.78 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtr, Xva, Ytr, Yva = train_test_split(X_ids, Y_1h, test_size=0.2, random_state=SEED, stratify=y)\n",
    "\n",
    "inputs = keras.Input(shape=(SEQLEN,), dtype=\"int32\", name=\"char_ids\")\n",
    "x = layers.Embedding(input_dim=len(vocab), output_dim=EMB_DIM, mask_zero=True)(inputs)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(HID_DIM, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(len(INTENTS), activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b419b",
   "metadata": {},
   "source": [
    "# Train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e64b82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - accuracy: 0.4061 - loss: 1.8083 - val_accuracy: 0.6035 - val_loss: 1.4155\n",
      "Epoch 2/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7587 - loss: 1.1040 - val_accuracy: 0.8355 - val_loss: 0.8231\n",
      "Epoch 3/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-1s\u001b[0m -20427us/step - accuracy: 0.8535 - loss: 0.6381 - val_accuracy: 0.8615 - val_loss: 0.5114\n",
      "Epoch 4/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8916 - loss: 0.4180 - val_accuracy: 0.9030 - val_loss: 0.3768\n",
      "Epoch 5/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9188 - loss: 0.3180 - val_accuracy: 0.9359 - val_loss: 0.3076\n",
      "Epoch 6/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9340 - loss: 0.2632 - val_accuracy: 0.9446 - val_loss: 0.2653\n",
      "Epoch 7/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9418 - loss: 0.2280 - val_accuracy: 0.9463 - val_loss: 0.2366\n",
      "Epoch 8/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9476 - loss: 0.2029 - val_accuracy: 0.9429 - val_loss: 0.2157\n",
      "Epoch 9/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9517 - loss: 0.1838 - val_accuracy: 0.9481 - val_loss: 0.1993\n",
      "Epoch 10/10\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9548 - loss: 0.1686 - val_accuracy: 0.9498 - val_loss: 0.1859\n",
      "le patient est claire martin -> ('PATIENT_IDENTITE', 0.9662253260612488)\n",
      "site fid -> ('SITE_OPERATOIRE', 0.999393105506897)\n",
      "a 10h30 -> ('HEURE_PREVUE', 0.9996709823608398)\n",
      "bonjour -> ('OTHER', 0.9932548999786377)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    Xtr, Ytr,\n",
    "    validation_data=(Xva, Yva),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Petit test\n",
    "def predict_intent_text(txt: str):\n",
    "    t = normalize_text(txt)\n",
    "    ids = vectorizer(np.array([t]))\n",
    "    prob = model.predict(ids, verbose=0)[0]\n",
    "    k = int(np.argmax(prob))\n",
    "    return INTENTS[k], float(prob[k])\n",
    "\n",
    "for t in [\"le patient est claire martin\", \"site fid\", \"a 10h30\", \"bonjour\"]:\n",
    "    print(t, \"->\", predict_intent_text(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0921b9",
   "metadata": {},
   "source": [
    "# Export SavedModel -> TFLite (quantization dynamique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a25f2cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzj8m3p0u/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpzj8m3p0u/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpzj8m3p0u'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200), dtype=tf.int32, name='char_ids')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139804392095376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139804392091536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139804392093648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139804376531216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139804376531984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1762357013.028340   28249 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1762357013.029199   28249 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-11-05 16:36:53.035216: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpzj8m3p0u\n",
      "2025-11-05 16:36:53.036582: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-11-05 16:36:53.036665: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpzj8m3p0u\n",
      "I0000 00:00:1762357013.052851   28249 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n",
      "2025-11-05 16:36:53.054467: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-11-05 16:36:53.111583: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpzj8m3p0u\n",
      "2025-11-05 16:36:53.128807: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 93724 microseconds.\n",
      "2025-11-05 16:36:53.364647: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# Pas besoin d’appeler model.save() avant\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # quantization dynamique (facultatif)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"intent_classifier.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# (labels/vocab restent inchangés)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfd14ac",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7551c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"PATIENT_IDENTITE\",', 0.9954239726066589)\n",
      "('\"SITE_OPERATOIRE\",', 0.9898533225059509)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, unicodedata, re, tensorflow as tf\n",
    "\n",
    "SEQLEN = 200  # même valeur que lors de l'entraînement\n",
    "\n",
    "def strip_accents(s): \n",
    "    import unicodedata\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c)!='Mn')\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    s = strip_accents(s)\n",
    "    s = re.sub(r'[^a-z0-9:/ \\-]', ' ', s)\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "# Charger vocab et labels exportés\n",
    "with open(\"char_vocab.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab = [line.rstrip(\"\\n\") for line in f]\n",
    "tok2id = {tok:i for i,tok in enumerate(vocab)}  # 0=\"\" padding, 1=\"[UNK]\"\n",
    "\n",
    "with open(\"intents.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    LABELS = [line.rstrip(\"\\n\") for line in f]\n",
    "\n",
    "def vectorize_chars(text: str, seqlen=SEQLEN):\n",
    "    t = normalize_text(text)\n",
    "    chars = list(t)  # split caractère\n",
    "    ids = np.zeros((1, seqlen), dtype=np.int32)\n",
    "    for i, ch in enumerate(chars[:seqlen]):\n",
    "        ids[0, i] = tok2id.get(ch, tok2id.get(\"[UNK]\", 1))\n",
    "    return ids\n",
    "\n",
    "# Charger le modèle TFLite\n",
    "interpreter = tf.lite.Interpreter(model_path=\"intent_classifier.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def predict_intent_tflite(text: str):\n",
    "    x = vectorize_chars(text)\n",
    "    interpreter.set_tensor(input_details[0]['index'], x)  # int32 [1, SEQLEN]\n",
    "    interpreter.invoke()\n",
    "    probs = interpreter.get_tensor(output_details[0]['index'])[0]  # float32 [num_labels]\n",
    "    k = int(np.argmax(probs))\n",
    "    return LABELS[k], float(probs[k])\n",
    "\n",
    "print(predict_intent_tflite(\"le patient est Paul Durant\"))\n",
    "print(predict_intent_tflite(\"site thoracique\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e58daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altusafe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
