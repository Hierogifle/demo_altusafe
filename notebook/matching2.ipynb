{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07be058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 15:05:44.660633: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — imports & helpers\n",
    "import os, re, unicodedata, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Reproductibilité\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# Normalisation texte\n",
    "def strip_accents(s: str) -> str:\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    s = strip_accents(s)\n",
    "    s = re.sub(r\"[^a-z0-9:/ \\-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ff845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             U             V  label\n",
      "0  le patient est chloe dupont  chloe dupont    1.0\n",
      "1  le patient est chloe dupont  dupont chloe    1.0\n",
      "2  le patient est chloe dupont        dupont    1.0\n",
      "3  le patient est chloe dupont         chloe    1.0\n",
      "4  le patient est chloe dupont         18:30    0.0\n",
      "Total pairs: 180000 | positives: 76000 | negatives: 104000\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — load TSV\n",
    "TSV_PATH = \"../data/pairs_checklist_180k.tsv\"  # ⬅️ adapte le chemin si besoin\n",
    "\n",
    "df = pd.read_csv(TSV_PATH, sep=\"\\t\", header=None, names=[\"U\",\"V\",\"label\"], dtype=str)\n",
    "# Nettoyage doux\n",
    "df[\"U\"] = df[\"U\"].astype(str).map(norm)\n",
    "df[\"V\"] = df[\"V\"].astype(str).map(norm)\n",
    "df[\"label\"] = df[\"label\"].astype(float)\n",
    "\n",
    "print(df.head())\n",
    "print(\"Total pairs:\", len(df), \"| positives:\", int((df['label']==1.0).sum()), \"| negatives:\", int((df['label']==0.0).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26f5767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample:\n",
      "je repete lina petit | cholecystectomie => 0.0\n",
      "le patient est ava da silva | nguyen => 0.0\n",
      "a 18h00 | durand => 0.0\n",
      "type prothese hanche | prothese hanche => 1.0\n",
      "intervention arthroscopie genou | bloc 2 => 0.0\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 — lists + shuffle\n",
    "U = df[\"U\"].tolist()\n",
    "V = df[\"V\"].tolist()\n",
    "y = df[\"label\"].astype(float).tolist()\n",
    "\n",
    "U, V, y = shuffle(U, V, y, random_state=SEED)\n",
    "\n",
    "print(\"Sample:\")\n",
    "for i in range(5):\n",
    "    print(U[i], \"|\", V[i], \"=>\", y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd89dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 13:33:30.144878: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 39\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 — char vectorizer\n",
    "SEQLEN = 200\n",
    "MAX_TOKENS = 300  # vocab taille max (caractères)\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    standardize=None,\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQLEN,\n",
    "    max_tokens=MAX_TOKENS\n",
    ")\n",
    "vectorizer.adapt(np.array(U + V))  # IMPORTANT: adapter sur tout le texte\n",
    "\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "# Sauvegarde pour Android\n",
    "with open(\"char_vocab_embed.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f70027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenitra/.pyenv/versions/altusafe/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"char_encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"char_encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">194</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ unit_normalization              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UnitNormalization</span>)             │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m2,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m20,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m194\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ unit_normalization              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mUnitNormalization\u001b[0m)             │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,744</span> (186.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,744\u001b[0m (186.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,744</span> (186.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,744\u001b[0m (186.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ——— Cellule 6 (fix Keras 3) : encodeur compact (chars → 128d, L2-normalisé) ———\n",
    "def build_encoder(vocab_size, seqlen, emb_dim=64, hid=64, out_dim=128):\n",
    "    inp = keras.Input(shape=(seqlen,), dtype=\"int32\")\n",
    "    x = layers.Embedding(vocab_size, emb_dim, mask_zero=True)(inp)\n",
    "    x = layers.Conv1D(64, 5, activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(hid, activation=\"relu\")(x)\n",
    "    x = layers.Dense(out_dim, use_bias=False)(x)\n",
    "    x = layers.UnitNormalization(axis=-1)(x)\n",
    "    return keras.Model(inp, x, name=\"char_encoder\")\n",
    "\n",
    "encoder = build_encoder(len(vocab), SEQLEN)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fb2ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 200) (256, 200) (256,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 13:34:15.331466: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 — TF datasets\n",
    "def make_pairs_dataset(U, V, y, batch=256, val_split=0.1):\n",
    "    # Vectoriser en numpy avec TextVectorization Keras (léger coût CPU)\n",
    "    X1 = vectorizer(np.array(U)).numpy()\n",
    "    X2 = vectorizer(np.array(V)).numpy()\n",
    "    y_arr = np.array(y, dtype=np.float32)\n",
    "\n",
    "    n = len(y_arr)\n",
    "    cut = int(n * (1 - val_split))\n",
    "    X1_tr, X2_tr, y_tr = X1[:cut], X2[:cut], y_arr[:cut]\n",
    "    X1_va, X2_va, y_va = X1[cut:], X2[cut:], y_arr[cut:]\n",
    "\n",
    "    def ds(x1, x2, yy):\n",
    "        d = tf.data.Dataset.from_tensor_slices(((x1, x2), yy))\n",
    "        return d.shuffle(8192, seed=SEED).batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds(X1_tr, X2_tr, y_tr), ds(X1_va, X2_va, y_va)\n",
    "\n",
    "train_ds, val_ds = make_pairs_dataset(U, V, y, batch=256, val_split=0.1)\n",
    "for (x1b, x2b), yb in train_ds.take(1):\n",
    "    print(x1b.shape, x2b.shape, yb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ddbd7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 223ms/step - AUC: 0.9965 - accuracy: 0.9875 - loss: 0.0543 - val_AUC: 1.0000 - val_accuracy: 0.9988 - val_loss: 0.0072\n",
      "Epoch 2/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 214ms/step - AUC: 1.0000 - accuracy: 0.9986 - loss: 0.0079 - val_AUC: 1.0000 - val_accuracy: 0.9983 - val_loss: 0.0067\n",
      "Epoch 3/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 209ms/step - AUC: 1.0000 - accuracy: 0.9990 - loss: 0.0065 - val_AUC: 1.0000 - val_accuracy: 0.9996 - val_loss: 0.0054\n",
      "Epoch 4/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 210ms/step - AUC: 1.0000 - accuracy: 0.9992 - loss: 0.0059 - val_AUC: 1.0000 - val_accuracy: 0.9988 - val_loss: 0.0058\n",
      "Epoch 5/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 209ms/step - AUC: 1.0000 - accuracy: 0.9994 - loss: 0.0055 - val_AUC: 1.0000 - val_accuracy: 0.9996 - val_loss: 0.0051\n",
      "Epoch 6/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 218ms/step - AUC: 1.0000 - accuracy: 0.9995 - loss: 0.0051 - val_AUC: 1.0000 - val_accuracy: 0.9997 - val_loss: 0.0042\n",
      "Epoch 7/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 212ms/step - AUC: 1.0000 - accuracy: 0.9994 - loss: 0.0049 - val_AUC: 1.0000 - val_accuracy: 0.9997 - val_loss: 0.0037\n",
      "Epoch 8/8\n",
      "\u001b[1m633/633\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 209ms/step - AUC: 1.0000 - accuracy: 0.9995 - loss: 0.0045 - val_AUC: 1.0000 - val_accuracy: 0.9998 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 — Siamese with cosine ≡ dot (vectors L2-normalized)\n",
    "u_in = keras.Input(shape=(SEQLEN,), dtype=\"int32\")\n",
    "v_in = keras.Input(shape=(SEQLEN,), dtype=\"int32\")\n",
    "\n",
    "u_vec = encoder(u_in)\n",
    "v_vec = encoder(v_in)\n",
    "\n",
    "# cos = dot because of UnitNormalization\n",
    "cos = layers.Dot(axes=1, name=\"cosine_dot\")([u_vec, v_vec])  # [B,1]\n",
    "\n",
    "# Learnable scale α using Dense(1) without bias (init ~10)\n",
    "scale = layers.Dense(1, use_bias=False,\n",
    "                     kernel_initializer=keras.initializers.Constant(10.0),\n",
    "                     name=\"scale_alpha\")\n",
    "logits = scale(cos)                          # [B,1]\n",
    "out = layers.Activation(\"sigmoid\", name=\"prob\")(logits)\n",
    "\n",
    "siamese = keras.Model([u_in, v_in], out, name=\"siamese_cosine\")\n",
    "\n",
    "siamese.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\", keras.metrics.AUC(name=\"AUC\")])\n",
    "\n",
    "history = siamese.fit(train_ds, validation_data=val_ds, epochs=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da4e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdtna6iq4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdtna6iq4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpdtna6iq4'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200), dtype=tf.int32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 128), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140497700289808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140497664737552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140497664737360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140497664740432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140497664741584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140497664741968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140497664741008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140497664742160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✅ Export OK → encoder_embed.tflite | char_vocab_embed.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "W0000 00:00:1762433685.226142   39141 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "W0000 00:00:1762433685.226524   39141 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-11-06 13:54:45.230083: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpdtna6iq4\n",
      "2025-11-06 13:54:45.231996: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-11-06 13:54:45.232044: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpdtna6iq4\n",
      "I0000 00:00:1762433685.249934   39141 mlir_graph_optimization_pass.cc:437] MLIR V1 optimization pass is not enabled\n",
      "2025-11-06 13:54:45.253074: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-11-06 13:54:45.317436: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpdtna6iq4\n",
      "2025-11-06 13:54:45.342139: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 112022 microseconds.\n",
      "2025-11-06 13:54:45.542499: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 — Export TFLite (encoder only)\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(encoder)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # quant dynamic\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"encoder_embed.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Vocab déjà sauvé en Cell 4 -> char_vocab_embed.txt\n",
    "print(\"✅ Export OK → encoder_embed.tflite | char_vocab_embed.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b1f2040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenitra/.pyenv/versions/altusafe/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 — TFLite inference helpers (batch & resize)\n",
    "interpreter = tf.lite.Interpreter(model_path=\"encoder_embed.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "_in = interpreter.get_input_details()\n",
    "_out = interpreter.get_output_details()\n",
    "SEQLEN = int(_in[0][\"shape\"][1])  # doit être 200\n",
    "\n",
    "# Charger vocab\n",
    "with open(\"char_vocab_embed.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    vocab = [l.rstrip(\"\\n\") for l in f]\n",
    "tok2id = {t:i for i,t in enumerate(vocab)}\n",
    "UNK = tok2id.get(\"[UNK]\", 1)\n",
    "\n",
    "def vectorize_texts(texts, seqlen=SEQLEN):\n",
    "    X = np.zeros((len(texts), seqlen), dtype=np.int32)\n",
    "    for i, t in enumerate(texts):\n",
    "        t = norm(t)\n",
    "        for j, ch in enumerate(t[:seqlen]):\n",
    "            X[i, j] = tok2id.get(ch, UNK)\n",
    "    return X\n",
    "\n",
    "def embed_texts(texts):\n",
    "    X = vectorize_texts(texts, SEQLEN)\n",
    "    # resize to [N, SEQLEN]\n",
    "    interpreter.resize_tensor_input(_in[0]['index'], [len(texts), SEQLEN])\n",
    "    interpreter.allocate_tensors()\n",
    "    in_d = interpreter.get_input_details()[0]\n",
    "    out_d = interpreter.get_output_details()[0]\n",
    "    interpreter.set_tensor(in_d['index'], X)\n",
    "    interpreter.invoke()\n",
    "    return interpreter.get_tensor(out_d['index'])  # [N, 128]\n",
    "\n",
    "def cosine(a, b):\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-9))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c7bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 — span search to avoid dilution on long utterances\n",
    "def word_windows(text, min_w=2, max_w=6):\n",
    "    toks = norm(text).split()\n",
    "    if not toks:\n",
    "        return [norm(text)]\n",
    "    spans = []\n",
    "    for w in range(min_w, min(max_w, len(toks)) + 1):\n",
    "        for i in range(0, len(toks) - w + 1):\n",
    "            spans.append(' '.join(toks[i:i+w]))\n",
    "    return spans or [norm(text)]\n",
    "\n",
    "# def best_cosine_over_spans(utterance: str, candidate: str):\n",
    "#     spans = word_windows(utterance, 2, 6)\n",
    "#     E_spans = embed_texts(spans)       # batch\n",
    "#     E_cand = embed_texts([candidate])[0]\n",
    "#     # cosines\n",
    "#     dots = (E_spans @ E_cand) / (np.linalg.norm(E_spans, axis=1) * np.linalg.norm(E_cand) + 1e-9)\n",
    "#     j = int(np.argmax(dots))\n",
    "#     return float(dots[j]), spans[j]\n",
    "\n",
    "# # Demo\n",
    "# utter = \"Opération en salle trois\"\n",
    "# cands = [\"Paul Dupont\", \"Dupont Paul\", \"10:30\", \"Salle 3\", \"Dr. Lefevre\", \"Appendicectomie\"]\n",
    "\n",
    "# for c in cands:\n",
    "#     s, span = best_cosine_over_spans(utter, c)\n",
    "#     print(f\"{c:20s} → {s:.3f} | best span: '{span}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14ac1ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dupont Paul          | 1.000 | OK | span='dupont paul'\n",
      "Salle 3              | 0.992 | OK | span='demarrage 10h30'\n",
      "Paul Dupont          | 0.985 | OK | span='dupont paul'\n",
      "10:30                | 0.963 | OK | span='demarrage 10h30'\n",
      "Dr. Bernard          | -0.059 | KO | span='ok demarrage'\n",
      "Appendicectomie      | -0.222 | KO | span='demarrage 10h30'\n"
     ]
    }
   ],
   "source": [
    "# # Cell 11 — decision thresholds\n",
    "# def decide(score: float, ok=0.88, maybe=0.70):\n",
    "#     return \"OK\" if score >= ok else (\"INCERTAIN\" if score >= maybe else \"KO\")\n",
    "\n",
    "# def match_utterance_to_candidates(utterance: str, candidates: list):\n",
    "#     results = []\n",
    "#     for c in candidates:\n",
    "#         s, span = best_cosine_over_spans(utterance, c)\n",
    "#         results.append((c, s, span, decide(s)))\n",
    "#     # tri par score décroissant\n",
    "#     results.sort(key=lambda x: -x[1])\n",
    "#     return results\n",
    "\n",
    "# # Demo decision\n",
    "# res = match_utterance_to_candidates(\n",
    "#     \"patient dupont paul confirmé, bloc trois ok, démarrage 10h30\",\n",
    "#     [\"Paul Dupont\", \"Dupont Paul\", \"10:30\", \"Salle 3\", \"Dr. Bernard\", \"Appendicectomie\"]\n",
    "# )\n",
    "# for c, s, span, dec in res:\n",
    "#     print(f\"{c:20s} | {s:.3f} | {dec} | span='{span}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f529aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfa704fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- utilitaires n-gram char ---\n",
    "import math, numpy as np, re, unicodedata\n",
    "\n",
    "def char_ngrams(s, n=3):\n",
    "    s = \" \" + s + \" \"\n",
    "    out = {}\n",
    "    for i in range(max(0, len(s)-n+1)):\n",
    "        g = s[i:i+n]\n",
    "        out[g] = out.get(g, 0) + 1\n",
    "    return out\n",
    "\n",
    "def cosine_counts(a, b):\n",
    "    keys = set(a.keys()) | set(b.keys())\n",
    "    dot = sum(a.get(k,0)*b.get(k,0) for k in keys)\n",
    "    na = math.sqrt(sum(v*v for v in a.values()))\n",
    "    nb = math.sqrt(sum(v*v for v in b.values()))\n",
    "    return 0.0 if na==0 or nb==0 else dot/(na*nb)\n",
    "\n",
    "def ngram_sim(u, v):\n",
    "    u = norm(u); v = norm(v)\n",
    "    return (cosine_counts(char_ngrams(u,3), char_ngrams(v,3)) +\n",
    "            cosine_counts(char_ngrams(u,4), char_ngrams(v,4)) +\n",
    "            cosine_counts(char_ngrams(u,5), char_ngrams(v,5))) / 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9051a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- spans qui doivent contenir au moins 1 token du candidat (optionnel mais recommandé pour NOMS) ---\n",
    "def best_cosine_over_spans_with_overlap(utterance: str, candidate: str, require_overlap_tokens=True):\n",
    "    spans = word_windows(utterance, 2, 6)\n",
    "    cand_tokens = set(norm(candidate).split())\n",
    "    filtered = []\n",
    "    if require_overlap_tokens:\n",
    "        for sp in spans:\n",
    "            if len(cand_tokens & set(sp.split())) > 0:\n",
    "                filtered.append(sp)\n",
    "    spans_eval = filtered if filtered else spans  # fallback si rien ne matche\n",
    "\n",
    "    E_spans = embed_texts(spans_eval)\n",
    "    E_cand = embed_texts([candidate])[0]\n",
    "    dots = (E_spans @ E_cand) / (np.linalg.norm(E_spans, axis=1)*np.linalg.norm(E_cand)+1e-9)\n",
    "    j = int(np.argmax(dots))\n",
    "    best_span = spans_eval[j]\n",
    "    embed_score = float(dots[j])\n",
    "\n",
    "    # score hybride (embed + n-gram)\n",
    "    ng = ngram_sim(best_span, candidate)\n",
    "    final = 0.7*embed_score + 0.3*ng\n",
    "    return final, best_span, embed_score, ng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fe28d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- décision + wrapper multi-candidats ---\n",
    "def decide(score: float, ok=0.88, maybe=0.70):\n",
    "    return \"OK\" if score >= ok else (\"INCERTAIN\" if score >= maybe else \"KO\")\n",
    "\n",
    "def match_utterance_to_candidates(utterance: str, candidates: list, require_overlap_for_names=True):\n",
    "    results = []\n",
    "    for c in candidates:\n",
    "        # Heuristique \"candidat ressemble à un nom de personne ?\"\n",
    "        tokens = norm(c).split()\n",
    "        is_name = len(tokens) >= 2 and all(t.isalpha() for t in tokens[:2])\n",
    "        req = (require_overlap_for_names and is_name)\n",
    "        s, span, s_embed, s_ng = best_cosine_over_spans_with_overlap(utterance, c, require_overlap_tokens=req)\n",
    "        results.append((c, s, span, decide(s), s_embed, s_ng))\n",
    "    results.sort(key=lambda x: -x[1])\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c40eb731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Dupont          | 1.000 | OK | span='paul dupont' | embed=1.000 | ng=1.000\n",
      "Dr. Bernard          | 1.000 | OK | span='dr bernard' | embed=1.000 | ng=1.000\n",
      "Dupont Paul          | 0.918 | OK | span='est paul dupont' | embed=0.988 | ng=0.755\n",
      "Romuald Bruno        | 0.612 | KO | span='avec le' | embed=0.874 | ng=0.000\n",
      "Appendicectomie      | 0.603 | KO | span='dr bernard' | embed=0.861 | ng=0.000\n",
      "Bruno Romuald        | 0.597 | KO | span='heures trente' | embed=0.854 | ng=0.000\n",
      "Salle 4              | 0.035 | KO | span='a dix' | embed=0.050 | ng=0.000\n",
      "10:30                | -0.081 | KO | span='a dix' | embed=-0.116 | ng=0.000\n"
     ]
    }
   ],
   "source": [
    "res = match_utterance_to_candidates(\n",
    "    \"Le patient est Paul Dupont, opération à dix heures trente en salle quatre avec le Dr. Bernard\",\n",
    "    [\"Bruno Romuald\", \"Romuald Bruno\", \"Paul Dupont\", \"Dupont Paul\", \"10:30\", \"Salle 4\", \"Dr. Bernard\", \"Appendicectomie\"]\n",
    ")\n",
    "\n",
    "for c, s, span, dec, s_embed, s_ng in res:\n",
    "    print(f\"{c:20s} | {s:.3f} | {dec} | span='{span}' | embed={s_embed:.3f} | ng={s_ng:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5d8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell X — use MatchEngine from src/match.py\n",
    "import os, sys\n",
    "# ensure src is on path so we can import match.py\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "from match import MatchEngine\n",
    "\n",
    "# Try a few likely locations for the tflite model and vocab (notebook cwd, ../src)\n",
    "tries = [\n",
    "    ('encoder_embed.tflite', 'char_vocab_embed.txt'),\n",
    "    (os.path.join('..','src','encoder_embed.tflite'), os.path.join('..','src','char_vocab_embed.txt')),\n",
    "    (os.path.join('..','src','encoder_embed.tflite'), 'char_vocab_embed.txt'),\n",
    "    ('encoder_embed.tflite', os.path.join('..','src','char_vocab_embed.txt'))\n",
    "]\n",
    "me = None\n",
    "last_exc = None\n",
    "for tfl, vocab in tries:\n",
    "    try:\n",
    "        me = MatchEngine(tflite_path=tfl, vocab_path=vocab)\n",
    "        print('Loaded MatchEngine with', tfl, vocab)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_exc = e\n",
    "        # continue to next candidate path\n",
    "\n",
    "if me is None:\n",
    "    raise last_exc\n",
    "\n",
    "# Sample utterance and candidates to match\n",
    "utter = 'Le patient est Paul Dupont, opération à dix heures trente en salle quatre avec le Dr. Bernard'\n",
    "candidates = [\"Bruno Romuald\", \"Romuald Bruno\", \"Paul Dupont\", \"Dupont Paul\", \"10:30\", \"Salle 4\", \"Dr. Bernard\", \"Appendicectomie\"]\n",
    "\n",
    "res = me.match_utterance_to_candidates(utter, candidates)\n",
    "for c, s, span, dec, s_embed, s_ng in res:\n",
    "    print(f\"{c:20s} | {s:.3f} | {dec} | span='{span}' | embed={s_embed:.3f} | ng={s_ng:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d6f1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altusafe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
