{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be058b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 13:28:15.561517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1 — imports & helpers\n",
    "import os, re, unicodedata, random, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Reproductibilité\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)\n",
    "\n",
    "# Normalisation texte\n",
    "def strip_accents(s: str) -> str:\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    s = s.lower().strip()\n",
    "    s = strip_accents(s)\n",
    "    s = re.sub(r\"[^a-z0-9:/ \\-]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ff845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             U             V  label\n",
      "0  le patient est chloe dupont  chloe dupont    1.0\n",
      "1  le patient est chloe dupont  dupont chloe    1.0\n",
      "2  le patient est chloe dupont        dupont    1.0\n",
      "3  le patient est chloe dupont         chloe    1.0\n",
      "4  le patient est chloe dupont         18:30    0.0\n",
      "Total pairs: 180000 | positives: 76000 | negatives: 104000\n"
     ]
    }
   ],
   "source": [
    "# Cell 2 — load TSV\n",
    "TSV_PATH = \"../data/pairs_checklist_180k.tsv\"  # ⬅️ adapte le chemin si besoin\n",
    "\n",
    "df = pd.read_csv(TSV_PATH, sep=\"\\t\", header=None, names=[\"U\",\"V\",\"label\"], dtype=str)\n",
    "# Nettoyage doux\n",
    "df[\"U\"] = df[\"U\"].astype(str).map(norm)\n",
    "df[\"V\"] = df[\"V\"].astype(str).map(norm)\n",
    "df[\"label\"] = df[\"label\"].astype(float)\n",
    "\n",
    "print(df.head())\n",
    "print(\"Total pairs:\", len(df), \"| positives:\", int((df['label']==1.0).sum()), \"| negatives:\", int((df['label']==0.0).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26f5767a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shuffle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m V = df[\u001b[33m\"\u001b[39m\u001b[33mV\u001b[39m\u001b[33m\"\u001b[39m].tolist()\n\u001b[32m      4\u001b[39m y = df[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mfloat\u001b[39m).tolist()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m U, V, y = \u001b[43mshuffle\u001b[49m(U, V, y, random_state=SEED)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSample:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n",
      "\u001b[31mNameError\u001b[39m: name 'shuffle' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 3 — lists + shuffle\n",
    "U = df[\"U\"].tolist()\n",
    "V = df[\"V\"].tolist()\n",
    "y = df[\"label\"].astype(float).tolist()\n",
    "\n",
    "U, V, y = shuffle(U, V, y, random_state=SEED)\n",
    "\n",
    "print(\"Sample:\")\n",
    "for i in range(5):\n",
    "    print(U[i], \"|\", V[i], \"=>\", y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e32a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ——— Cellule 5 : vectorisation char-level identique Python/Android ———\n",
    "SEQLEN = 200\n",
    "VOCAB_SZ = 300\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    standardize=None, split=\"character\",\n",
    "    output_mode=\"int\", output_sequence_length=SEQLEN,\n",
    "    max_tokens=VOCAB_SZ\n",
    ")\n",
    "vectorizer.adapt(np.array(U + V))\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "with open(\"char_vocab_embed.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f70027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenitra/.pyenv/versions/altusafe/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"char_encoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"char_encoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">194</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ unit_normalization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UnitNormalization</span>)             │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m2,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m20,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m194\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m12,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ unit_normalization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mUnitNormalization\u001b[0m)             │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,744</span> (186.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m47,744\u001b[0m (186.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,744</span> (186.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m47,744\u001b[0m (186.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ——— Cellule 6 (fix Keras 3) : encodeur compact (chars → 128d, L2-normalisé) ———\n",
    "def build_encoder(vocab_size, seqlen, emb_dim=64, hid=64, out_dim=128):\n",
    "    inp = keras.Input(shape=(seqlen,), dtype=\"int32\")\n",
    "    x = layers.Embedding(vocab_size, emb_dim, mask_zero=True)(inp)\n",
    "    x = layers.Conv1D(64, 5, activation=\"relu\")(x)\n",
    "    x = layers.Conv1D(64, 3, activation=\"relu\")(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(hid, activation=\"relu\")(x)\n",
    "    x = layers.Dense(out_dim, use_bias=False)(x)\n",
    "    x = layers.UnitNormalization(axis=-1)(x)\n",
    "    return keras.Model(inp, x, name=\"char_encoder\")\n",
    "\n",
    "encoder = build_encoder(len(vocab), SEQLEN)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 187ms/step - AUC: 0.9489 - accuracy: 0.9160 - loss: 0.3191 - val_AUC: 0.9900 - val_accuracy: 0.9708 - val_loss: 0.1313\n",
      "Epoch 2/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 176ms/step - AUC: 0.9932 - accuracy: 0.9787 - loss: 0.1142 - val_AUC: 0.9965 - val_accuracy: 0.9825 - val_loss: 0.1019\n",
      "Epoch 3/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 176ms/step - AUC: 0.9962 - accuracy: 0.9834 - loss: 0.0956 - val_AUC: 0.9976 - val_accuracy: 0.9844 - val_loss: 0.0922\n",
      "Epoch 4/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 180ms/step - AUC: 0.9979 - accuracy: 0.9864 - loss: 0.0848 - val_AUC: 0.9984 - val_accuracy: 0.9881 - val_loss: 0.0816\n",
      "Epoch 5/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 175ms/step - AUC: 0.9987 - accuracy: 0.9881 - loss: 0.0794 - val_AUC: 0.9990 - val_accuracy: 0.9896 - val_loss: 0.0774\n",
      "Epoch 6/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 176ms/step - AUC: 0.9992 - accuracy: 0.9893 - loss: 0.0734 - val_AUC: 0.9990 - val_accuracy: 0.9898 - val_loss: 0.0760\n",
      "Epoch 7/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 179ms/step - AUC: 0.9995 - accuracy: 0.9904 - loss: 0.0696 - val_AUC: 0.9989 - val_accuracy: 0.9907 - val_loss: 0.0724\n",
      "Epoch 8/8\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 171ms/step - AUC: 0.9996 - accuracy: 0.9912 - loss: 0.0665 - val_AUC: 0.9991 - val_accuracy: 0.9905 - val_loss: 0.0691\n"
     ]
    }
   ],
   "source": [
    "# ——— Cellule 7 (fix Keras 3) : Siamese head (cosine ≡ dot + BCE) ———\n",
    "def make_pairs_dataset(U, V, y, batch=256, val_split=0.1):\n",
    "    X1 = vectorizer(np.array(U)).numpy()\n",
    "    X2 = vectorizer(np.array(V)).numpy()\n",
    "    idx = np.arange(len(y)); np.random.shuffle(idx)\n",
    "    cut = int(len(y)*(1-val_split))\n",
    "    tr, va = idx[:cut], idx[cut:]\n",
    "\n",
    "    def ds(x1,x2,y):\n",
    "        ds = tf.data.Dataset.from_tensor_slices(((x1,x2), y))\n",
    "        return ds.shuffle(8192).batch(batch).prefetch(2)\n",
    "    return ds(X1[tr],X2[tr],y[tr]), ds(X1[va],X2[va],y[va])\n",
    "\n",
    "train_ds, val_ds = make_pairs_dataset(U,V,y)\n",
    "\n",
    "# Inputs\n",
    "u_in = keras.Input(shape=(SEQLEN,), dtype=\"int32\")\n",
    "v_in = keras.Input(shape=(SEQLEN,), dtype=\"int32\")\n",
    "u_vec = encoder(u_in)\n",
    "v_vec = encoder(v_in)\n",
    "cos = layers.Dot(axes=1, name=\"cosine_dot\")([u_vec, v_vec])\n",
    "scale = layers.Dense(1, use_bias=False,\n",
    "                     kernel_initializer=keras.initializers.Constant(10.0))\n",
    "logits = scale(cos)\n",
    "out = layers.Activation(\"sigmoid\")(logits)\n",
    "\n",
    "siamese = keras.Model([u_in, v_in], out)\n",
    "siamese.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\",\"AUC\"])\n",
    "history = siamese.fit(train_ds, validation_data=val_ds, epochs=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4e280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenitra/.pyenv/versions/altusafe/lib/python3.12/site-packages/keras/src/layers/layer.py:970: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpko9u17f8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpko9u17f8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/tmp/tmpko9u17f8'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 200), dtype=tf.int32, name='keras_tensor_27')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 128), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140009229496976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140010767950928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140009229497360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140009229498896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140009229498128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140009229494096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140009229500240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140009229500048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1762427026.172773   16259 tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export OK → encoder_embed.tflite + char_vocab_embed.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1762427026.173096   16259 tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-11-06 12:03:46.173748: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpko9u17f8\n",
      "2025-11-06 12:03:46.174696: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-11-06 12:03:46.174721: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpko9u17f8\n",
      "2025-11-06 12:03:46.179561: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-11-06 12:03:46.208423: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpko9u17f8\n",
      "2025-11-06 12:03:46.216687: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 42945 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# ——— Cellule 8 : Export TFLite du modèle encodeur (quantized) ———\n",
    "\n",
    "# On n’exporte que l’encodeur, pas le Siamese complet\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(encoder)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # quantization dynamique (facultatif)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Sauvegarde du modèle TFLite\n",
    "with open(\"encoder_embed.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Sauvegarde du vocab utilisé pour la vectorisation (à embarquer sur Android)\n",
    "with open(\"char_vocab_embed.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(vocab))\n",
    "\n",
    "print(\"Export OK → encoder_embed.tflite + char_vocab_embed.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f2040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Dupont          → 0.486 (best span: 'de l')\n",
      "Dupont Paul          → 0.452 (best span: 'de l')\n",
      "10:30                → 0.382 (best span: 'de l')\n",
      "Salle 3              → 0.006 (best span: 'operation de l')\n",
      "Dr. Lefèvre          → 0.448 (best span: 'de l')\n",
      "Appendicectomie      → 0.979 (best span: 'l appendice')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fenitra/.pyenv/versions/altusafe/lib/python3.12/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, re, unicodedata, tensorflow as tf\n",
    "\n",
    "# Charger modèle TFLite + vocab\n",
    "interpreter = tf.lite.Interpreter(model_path=\"encoder_embed.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "in_det = interpreter.get_input_details(); out_det = interpreter.get_output_details()\n",
    "SEQLEN = int(in_det[0]['shape'][1])\n",
    "\n",
    "with open(\"char_vocab_embed.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    vocab=[l.strip() for l in f]\n",
    "tok2id={t:i for i,t in enumerate(vocab)}; UNK=tok2id.get(\"[UNK]\",1)\n",
    "\n",
    "def normalize_text(s):\n",
    "    s=s.lower().strip()\n",
    "    s=''.join(c for c in unicodedata.normalize('NFD',s) if unicodedata.category(c)!='Mn')\n",
    "    s=re.sub(r'[^a-z0-9:/ \\-]',' ',s); s=re.sub(r'\\s+',' ',s).strip()\n",
    "    return s\n",
    "\n",
    "def vectorize(texts):\n",
    "    X=np.zeros((len(texts),SEQLEN),dtype=np.int32)\n",
    "    for i,t in enumerate(texts):\n",
    "        t=normalize_text(t)\n",
    "        for j,ch in enumerate(t[:SEQLEN]):\n",
    "            X[i,j]=tok2id.get(ch,UNK)\n",
    "    return X\n",
    "\n",
    "def embed_texts(texts):\n",
    "    X=vectorize(texts)\n",
    "    interpreter.resize_tensor_input(in_det[0]['index'], [len(texts),SEQLEN])\n",
    "    interpreter.allocate_tensors()\n",
    "    in_d=interpreter.get_input_details()[0]; out_d=interpreter.get_output_details()[0]\n",
    "    interpreter.set_tensor(in_d['index'],X)\n",
    "    interpreter.invoke()\n",
    "    return interpreter.get_tensor(out_d['index'])\n",
    "\n",
    "def cosine(a,b): return float(np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b)+1e-9))\n",
    "\n",
    "# ---- Fenêtrisation ----\n",
    "def word_windows(text,min_w=2,max_w=6):\n",
    "    toks=normalize_text(text).split(); spans=[]\n",
    "    for w in range(min_w,min(max_w,len(toks))+1):\n",
    "        for i in range(0,len(toks)-w+1):\n",
    "            spans.append(' '.join(toks[i:i+w]))\n",
    "    return spans or [normalize_text(text)]\n",
    "\n",
    "def best_cosine_over_spans(utter,candidate):\n",
    "    spans=word_windows(utter)\n",
    "    e_sp=embed_texts(spans); e_c=embed_texts([candidate])[0]\n",
    "    dots=(e_sp@e_c)/(np.linalg.norm(e_sp,axis=1)*np.linalg.norm(e_c)+1e-9)\n",
    "    j=int(np.argmax(dots))\n",
    "    return float(dots[j]),spans[j]\n",
    "\n",
    "# ---- Démo ----\n",
    "utter=\"opération de l'appendice\"\n",
    "cands=[\"Paul Dupont\",\"Dupont Paul\",\"10:30\",\"Salle 3\",\"Dr. Lefèvre\",\"Appendicectomie\"]\n",
    "\n",
    "for c in cands:\n",
    "    s,span=best_cosine_over_spans(utter,c)\n",
    "    print(f\"{c:20s} → {s:.3f} (best span: '{span}')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7bc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altusafe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
